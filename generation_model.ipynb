{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4549051,"sourceType":"datasetVersion","datasetId":2655917}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-10T11:00:46.484677Z","iopub.execute_input":"2025-05-10T11:00:46.484856Z","iopub.status.idle":"2025-05-10T11:00:49.674159Z","shell.execute_reply.started":"2025-05-10T11:00:46.484839Z","shell.execute_reply":"2025-05-10T11:00:49.673239Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip uninstall bitsandbytes -y\n\n!pip install -U bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T11:00:56.007163Z","iopub.execute_input":"2025-05-10T11:00:56.007937Z","iopub.status.idle":"2025-05-10T11:02:32.664138Z","shell.execute_reply.started":"2025-05-10T11:00:56.007904Z","shell.execute_reply":"2025-05-10T11:02:32.663197Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import bitsandbytes\nprint(bitsandbytes.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T11:02:32.665660Z","iopub.execute_input":"2025-05-10T11:02:32.665910Z","iopub.status.idle":"2025-05-10T11:02:41.703585Z","shell.execute_reply.started":"2025-05-10T11:02:32.665887Z","shell.execute_reply":"2025-05-10T11:02:41.702830Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install --upgrade bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T11:03:12.703822Z","iopub.execute_input":"2025-05-10T11:03:12.705026Z","iopub.status.idle":"2025-05-10T11:03:16.019266Z","shell.execute_reply.started":"2025-05-10T11:03:12.704996Z","shell.execute_reply":"2025-05-10T11:03:16.018417Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -U bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T11:03:22.658134Z","iopub.execute_input":"2025-05-10T11:03:22.658480Z","iopub.status.idle":"2025-05-10T11:03:25.990868Z","shell.execute_reply.started":"2025-05-10T11:03:22.658430Z","shell.execute_reply":"2025-05-10T11:03:25.989942Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install transformers datasets torch accelerate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T11:03:28.795345Z","iopub.execute_input":"2025-05-10T11:03:28.796232Z","iopub.status.idle":"2025-05-10T11:03:33.034227Z","shell.execute_reply.started":"2025-05-10T11:03:28.796202Z","shell.execute_reply":"2025-05-10T11:03:33.032622Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install transformers datasets torch pandas evaluate rouge_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T11:03:34.930778Z","iopub.execute_input":"2025-05-10T11:03:34.931660Z","iopub.status.idle":"2025-05-10T11:03:41.212768Z","shell.execute_reply.started":"2025-05-10T11:03:34.931625Z","shell.execute_reply":"2025-05-10T11:03:41.211981Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install huggingface_hub","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T09:10:07.985326Z","iopub.execute_input":"2025-05-10T09:10:07.985626Z","iopub.status.idle":"2025-05-10T09:10:11.132178Z","shell.execute_reply.started":"2025-05-10T09:10:07.985579Z","shell.execute_reply":"2025-05-10T09:10:11.131319Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom datasets import Dataset\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling\nfrom peft import LoraConfig, get_peft_model\nfrom transformers  import BitsAndBytesConfig\nimport torch\nfrom torch.utils.data import DataLoader\nfrom huggingface_hub import login\nimport torch.nn as nn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T11:03:41.214499Z","iopub.execute_input":"2025-05-10T11:03:41.214778Z","iopub.status.idle":"2025-05-10T11:04:12.431562Z","shell.execute_reply.started":"2025-05-10T11:03:41.214754Z","shell.execute_reply":"2025-05-10T11:04:12.430864Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Reading dataest","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/introducing-quail-a-comprehensive-reading-compre/train.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T11:48:36.340423Z","iopub.execute_input":"2025-05-10T11:48:36.341172Z","iopub.status.idle":"2025-05-10T11:48:36.931979Z","shell.execute_reply.started":"2025-05-10T11:48:36.341145Z","shell.execute_reply":"2025-05-10T11:48:36.931356Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_cleaned = df[[\"context\", \"question\", \"answers\"]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T11:48:37.651860Z","iopub.execute_input":"2025-05-10T11:48:37.652185Z","iopub.status.idle":"2025-05-10T11:48:37.658540Z","shell.execute_reply.started":"2025-05-10T11:48:37.652160Z","shell.execute_reply":"2025-05-10T11:48:37.657524Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_cleaned = df_cleaned[df_cleaned['question'].str.endswith('?', na=False)]\ndf_cleaned = df_cleaned.reset_index(drop=True)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T11:48:38.326783Z","iopub.execute_input":"2025-05-10T11:48:38.327158Z","iopub.status.idle":"2025-05-10T11:48:38.337200Z","shell.execute_reply.started":"2025-05-10T11:48:38.327135Z","shell.execute_reply":"2025-05-10T11:48:38.336368Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_task1 = df_cleaned.copy()\ndf_task1[\"input_text\"] = \"generate question: \" + df_cleaned[\"context\"]\ndf_task1[\"target_text\"] = \"Question: \" + df_cleaned[\"question\"] + \" Answer: \" + df_cleaned[\"answers\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T11:48:38.627084Z","iopub.execute_input":"2025-05-10T11:48:38.627861Z","iopub.status.idle":"2025-05-10T11:48:38.648649Z","shell.execute_reply.started":"2025-05-10T11:48:38.627836Z","shell.execute_reply":"2025-05-10T11:48:38.647994Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_task1.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T11:48:39.634501Z","iopub.execute_input":"2025-05-10T11:48:39.635156Z","iopub.status.idle":"2025-05-10T11:48:39.646189Z","shell.execute_reply.started":"2025-05-10T11:48:39.635132Z","shell.execute_reply":"2025-05-10T11:48:39.645189Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_task2 = df_cleaned.copy()\ndf_task2[\"input_text\"] = \"answer question: \" + df_cleaned[\"question\"] + \" context: \" + df_cleaned[\"context\"]\ndf_task2[\"target_text\"] = df_cleaned[\"answers\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T11:48:39.965709Z","iopub.execute_input":"2025-05-10T11:48:39.965959Z","iopub.status.idle":"2025-05-10T11:48:39.997614Z","shell.execute_reply.started":"2025-05-10T11:48:39.965941Z","shell.execute_reply":"2025-05-10T11:48:39.996837Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_combined = pd.concat([df_task1[[\"input_text\", \"target_text\"]], df_task2[[\"input_text\", \"target_text\"]]], ignore_index=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T11:48:41.383496Z","iopub.execute_input":"2025-05-10T11:48:41.384031Z","iopub.status.idle":"2025-05-10T11:48:41.408018Z","shell.execute_reply.started":"2025-05-10T11:48:41.384007Z","shell.execute_reply":"2025-05-10T11:48:41.407118Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_cleaned","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T11:48:41.954323Z","iopub.execute_input":"2025-05-10T11:48:41.955045Z","iopub.status.idle":"2025-05-10T11:48:41.964438Z","shell.execute_reply.started":"2025-05-10T11:48:41.955016Z","shell.execute_reply":"2025-05-10T11:48:41.963577Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Reformatting data","metadata":{}},{"cell_type":"code","source":"def reformat_df_cleaned(df_cleaned, task):\n    df_reformatted = df_cleaned.copy()\n    df_reformatted['parsed_answer'] = df_reformatted['answers'].apply(\n        lambda x: x.strip(\"[]\").split(\"'\")[1] if x else \"not enough information\"\n    )\n    \n    if task == \"qa_generation\":\n        df_reformatted['prompt'] = (\n            \"### Context:\\n\" + df_reformatted['context'] + \"\\n\\n\" +\n            \"### Instruction:\\nGenerate a question and its answer based on the context.\\n\\n\" +\n            \"### Output:\\n**Question**: \" + df_reformatted['question'] + \"\\n\" +\n            \"**Answer**: \" + df_reformatted['parsed_answer']\n        )\n    elif task == \"qa_answering\":\n        df_reformatted['prompt'] = (\n            \"### Context:\\n\" + df_reformatted['context'] + \"\\n\\n\" +\n            \"### Question:\\n\" + df_reformatted['question'] + \"\\n\\n\" +\n            \"### Instruction:\\nProvide the answer to the question based on the context.\\n\\n\" +\n            \"### Answer:\\n\" + df_reformatted['parsed_answer']\n        )\n    else:\n        raise ValueError(\"Task must be 'qa_generation' or 'qa_answering'\")\n    \n    df_reformatted = df_reformatted.drop(columns=['parsed_answer'])\n    return df_reformatted","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T11:48:43.588428Z","iopub.execute_input":"2025-05-10T11:48:43.589314Z","iopub.status.idle":"2025-05-10T11:48:43.594871Z","shell.execute_reply.started":"2025-05-10T11:48:43.589266Z","shell.execute_reply":"2025-05-10T11:48:43.594028Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df, val_df = train_test_split(df_cleaned, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T11:48:46.000654Z","iopub.execute_input":"2025-05-10T11:48:46.001311Z","iopub.status.idle":"2025-05-10T11:48:46.008098Z","shell.execute_reply.started":"2025-05-10T11:48:46.001289Z","shell.execute_reply":"2025-05-10T11:48:46.007232Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df, val_df = train_test_split(df_cleaned, test_size=0.2, random_state=42)\ntrain_df_qa_gen = reformat_df_cleaned(train_df, task=\"qa_generation\")\nval_df_qa_gen = reformat_df_cleaned(val_df, task=\"qa_generation\")\ntrain_df_qa_answer = reformat_df_cleaned(train_df, task=\"qa_answering\")\nval_df_qa_answer = reformat_df_cleaned(val_df, task=\"qa_answering\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T11:48:46.305042Z","iopub.execute_input":"2025-05-10T11:48:46.305740Z","iopub.status.idle":"2025-05-10T11:48:46.489044Z","shell.execute_reply.started":"2025-05-10T11:48:46.305714Z","shell.execute_reply":"2025-05-10T11:48:46.488481Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset_qa_gen = Dataset.from_pandas(train_df_qa_gen)\nval_dataset_qa_gen = Dataset.from_pandas(val_df_qa_gen)\ntrain_dataset_qa_answer = Dataset.from_pandas(train_df_qa_answer)\nval_dataset_qa_answer = Dataset.from_pandas(val_df_qa_answer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T11:48:46.589990Z","iopub.execute_input":"2025-05-10T11:48:46.590597Z","iopub.status.idle":"2025-05-10T11:48:47.094743Z","shell.execute_reply.started":"2025-05-10T11:48:46.590574Z","shell.execute_reply":"2025-05-10T11:48:47.094145Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"access_token = os.getenv(\"HF_TOKEN\")\nlogin(access_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T11:08:13.202830Z","iopub.execute_input":"2025-05-10T11:08:13.203208Z","iopub.status.idle":"2025-05-10T11:08:13.221153Z","shell.execute_reply.started":"2025-05-10T11:08:13.203183Z","shell.execute_reply":"2025-05-10T11:08:13.220216Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Tokenization","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T11:49:15.085846Z","iopub.execute_input":"2025-05-10T11:49:15.086164Z","iopub.status.idle":"2025-05-10T11:49:16.006860Z","shell.execute_reply.started":"2025-05-10T11:49:15.086140Z","shell.execute_reply":"2025-05-10T11:49:16.005958Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def tokenize_function(examples):\n    return tokenizer(\n        examples[\"prompt\"],\n        padding=\"max_length\",\n        truncation=True,\n        max_length=512,\n        return_tensors=\"pt\"\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T11:49:17.222356Z","iopub.execute_input":"2025-05-10T11:49:17.223128Z","iopub.status.idle":"2025-05-10T11:49:17.227102Z","shell.execute_reply.started":"2025-05-10T11:49:17.223105Z","shell.execute_reply":"2025-05-10T11:49:17.226373Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_qa_gen_tokenized = train_dataset_qa_gen.map(\n    tokenize_function,\n    batched=True,\n    remove_columns=[\"prompt\", \"context\", \"question\", \"answers\"]\n)\nval_qa_gen_tokenized = val_dataset_qa_gen.map(\n    tokenize_function,\n    batched=True,\n    remove_columns=[\"prompt\", \"context\", \"question\", \"answers\"]\n)\ntrain_qa_answer_tokenized = train_dataset_qa_answer.map(\n    tokenize_function,\n    batched=True,\n    remove_columns=[\"prompt\", \"context\", \"question\", \"answers\"]\n)\nval_qa_answer_tokenized = val_dataset_qa_answer.map(\n    tokenize_function,\n    batched=True,\n    remove_columns=[\"prompt\", \"context\", \"question\", \"answers\"]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T11:49:18.832369Z","iopub.execute_input":"2025-05-10T11:49:18.832693Z","iopub.status.idle":"2025-05-10T11:49:29.307228Z","shell.execute_reply.started":"2025-05-10T11:49:18.832670Z","shell.execute_reply":"2025-05-10T11:49:29.306462Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_qa_gen_tokenized.set_format(\"torch\")\nval_qa_gen_tokenized.set_format(\"torch\")\ntrain_qa_answer_tokenized.set_format(\"torch\")\nval_qa_answer_tokenized.set_format(\"torch\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T11:49:32.342843Z","iopub.execute_input":"2025-05-10T11:49:32.343920Z","iopub.status.idle":"2025-05-10T11:49:32.348918Z","shell.execute_reply.started":"2025-05-10T11:49:32.343867Z","shell.execute_reply":"2025-05-10T11:49:32.348315Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_use_double_quant=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T11:49:44.223724Z","iopub.execute_input":"2025-05-10T11:49:44.224311Z","iopub.status.idle":"2025-05-10T11:49:44.738441Z","shell.execute_reply.started":"2025-05-10T11:49:44.224286Z","shell.execute_reply":"2025-05-10T11:49:44.737613Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import gc\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T11:49:44.739690Z","iopub.execute_input":"2025-05-10T11:49:44.740384Z","iopub.status.idle":"2025-05-10T11:49:45.145529Z","shell.execute_reply.started":"2025-05-10T11:49:44.740364Z","shell.execute_reply":"2025-05-10T11:49:45.144847Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Quantization","metadata":{}},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(\n    \"mistralai/Mistral-7B-Instruct-v0.1\",\n    quantization_config=bnb_config,\n    device_map=\"auto\" \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T11:49:45.742300Z","iopub.execute_input":"2025-05-10T11:49:45.742977Z","iopub.status.idle":"2025-05-10T11:49:46.098754Z","shell.execute_reply.started":"2025-05-10T11:49:45.742951Z","shell.execute_reply":"2025-05-10T11:49:46.097508Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lora_config = LoraConfig(\n    r=8,\n    lora_alpha=16,\n    target_modules=[\"q_proj\", \"v_proj\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T18:14:59.253580Z","iopub.execute_input":"2025-05-09T18:14:59.253914Z","iopub.status.idle":"2025-05-09T18:14:59.258516Z","shell.execute_reply.started":"2025-05-09T18:14:59.253889Z","shell.execute_reply":"2025-05-09T18:14:59.257615Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = get_peft_model(model, lora_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T18:14:59.889958Z","iopub.execute_input":"2025-05-09T18:14:59.890237Z","iopub.status.idle":"2025-05-09T18:14:59.983888Z","shell.execute_reply.started":"2025-05-09T18:14:59.890216Z","shell.execute_reply":"2025-05-09T18:14:59.983262Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"batch_size = 1\ngradient_accumulation_steps = 16\nnum_train_epochs = 5\nlearning_rate = 2e-4\ndevice = torch.device(\"cuda:0\")\noutput_dir = \"./mistral_finetuned\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T11:50:06.571952Z","iopub.execute_input":"2025-05-10T11:50:06.572552Z","iopub.status.idle":"2025-05-10T11:50:06.576292Z","shell.execute_reply.started":"2025-05-10T11:50:06.572530Z","shell.execute_reply":"2025-05-10T11:50:06.575507Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T11:50:08.568331Z","iopub.execute_input":"2025-05-10T11:50:08.569139Z","iopub.status.idle":"2025-05-10T11:50:08.577480Z","shell.execute_reply.started":"2025-05-10T11:50:08.569110Z","shell.execute_reply":"2025-05-10T11:50:08.576755Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataloader_qa_gen = DataLoader(\n    train_qa_gen_tokenized,\n    batch_size=batch_size,\n    shuffle=True,\n    collate_fn=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n)\nval_dataloader_qa_gen = DataLoader(\n    val_qa_gen_tokenized,\n    batch_size=batch_size,\n    shuffle=False,\n    collate_fn=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n)\ntrain_dataloader_qa_answer = DataLoader(\n    train_qa_answer_tokenized,\n    batch_size=batch_size,\n    shuffle=True,\n    collate_fn=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n)\nval_dataloader_qa_answer = DataLoader(\n    val_qa_answer_tokenized,\n    batch_size=batch_size,\n    shuffle=False,\n    collate_fn=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T11:50:08.875177Z","iopub.execute_input":"2025-05-10T11:50:08.875783Z","iopub.status.idle":"2025-05-10T11:50:08.880983Z","shell.execute_reply.started":"2025-05-10T11:50:08.875758Z","shell.execute_reply":"2025-05-10T11:50:08.880042Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import gc\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T18:15:07.971920Z","iopub.execute_input":"2025-05-09T18:15:07.972578Z","iopub.status.idle":"2025-05-09T18:15:08.357760Z","shell.execute_reply.started":"2025-05-09T18:15:07.972556Z","shell.execute_reply":"2025-05-09T18:15:08.357028Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training model","metadata":{}},{"cell_type":"code","source":"def train_model(model, train_dataloader, val_dataloader, output_dir, task_name, repo_name, access_token):\n    model.train()\n    total_steps = len(train_dataloader) * num_train_epochs\n    step = 0\n\n    for epoch in range(num_train_epochs):\n        total_loss = 0\n        for batch_idx, batch in enumerate(train_dataloader):\n            try:\n                input_ids = batch[\"input_ids\"].to(model.device)\n                attention_mask = batch[\"attention_mask\"].to(model.device)\n                labels = batch[\"labels\"].to(model.device)\n\n                outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n                loss = outputs.loss\n                loss = loss / gradient_accumulation_steps \n                total_loss += loss.item()\n\n                loss.backward()\n\n                if (batch_idx + 1) % gradient_accumulation_steps == 0:\n                    optimizer.step()\n                    optimizer.zero_grad()\n                    step += 1\n                    if step % 20 == 0:\n                        print(f\"Epoch {epoch+1}, Step {step}/{total_steps}, Loss: {total_loss / (batch_idx + 1):.4f}\")\n\n                if (batch_idx + 1) == len(train_dataloader):\n                    model.eval()\n                    val_loss = 0\n                    with torch.no_grad():\n                        for val_batch in val_dataloader:\n                            input_ids = val_batch[\"input_ids\"].to(device)\n                            attention_mask = val_batch[\"attention_mask\"].to(device)\n                            labels = val_batch[\"labels\"].to(device)\n                            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n                            val_loss += outputs.loss.item()\n                    val_loss /= len(val_dataloader)\n                    print(f\"Epoch {epoch+1}, Validation Loss: {val_loss:.4f}\")\n                    model.train()\n\n            except RuntimeError as e:\n                print(f\"Error during training: {e}\")\n                torch.cuda.empty_cache()  \n                continue\n\n        local_save_path = f\"{output_dir}/{task_name}\"\n        model.save_pretrained(local_save_path)\n        tokenizer.save_pretrained(local_save_path)\n        print(f\"Model and tokenizer saved locally to {local_save_path}\")\n\n        try:\n            model.eval()\n            model.push_to_hub(repo_name, token=access_token)\n            tokenizer.push_to_hub(repo_name, token=access_token)\n            print(f\"Model and tokenizer successfully pushed to Hugging Face Hub: https://huggingface.co/{repo_name}\")\n        except Exception as e:\n            print(f\"Error pushing to Hugging Face Hub: {e}\")\n            print(\"Continuing without pushing to Hub...\")\n\nrepo_name_qa_gen = \"selsayed2003/mistral_qa_gen\" \nrepo_name_qa_answer = \"selsayed2003/mistral_qa_answer\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T08:53:29.398739Z","iopub.execute_input":"2025-05-10T08:53:29.398969Z","iopub.status.idle":"2025-05-10T08:53:29.412336Z","shell.execute_reply.started":"2025-05-10T08:53:29.398948Z","shell.execute_reply":"2025-05-10T08:53:29.411385Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Training QA Generation Model...\")\ntrain_model(model, train_dataloader_qa_gen, val_dataloader_qa_gen, output_dir, \"mistral_qa_gen\", repo_name_qa_gen, access_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T08:53:29.413495Z","iopub.execute_input":"2025-05-10T08:53:29.413806Z","iopub.status.idle":"2025-05-10T08:53:29.531328Z","shell.execute_reply.started":"2025-05-10T08:53:29.413777Z","shell.execute_reply":"2025-05-10T08:53:29.530012Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Loading model from hugging ","metadata":{}},{"cell_type":"code","source":"!pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T08:53:29.531912Z","iopub.status.idle":"2025-05-10T08:53:29.532177Z","shell.execute_reply.started":"2025-05-10T08:53:29.532054Z","shell.execute_reply":"2025-05-10T08:53:29.532066Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from peft import PeftModel\nfrom transformers import AutoModelForCausalLM, AutoTokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T11:33:45.859647Z","iopub.execute_input":"2025-05-10T11:33:45.859951Z","iopub.status.idle":"2025-05-10T11:33:45.863750Z","shell.execute_reply.started":"2025-05-10T11:33:45.859928Z","shell.execute_reply":"2025-05-10T11:33:45.862974Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_model_id = \"mistralai/Mistral-7B-Instruct-v0.1\"  \nadapter_id = \"selsayed2003/mistral_qa_gen\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T11:33:51.443823Z","iopub.execute_input":"2025-05-10T11:33:51.444424Z","iopub.status.idle":"2025-05-10T11:33:51.447984Z","shell.execute_reply.started":"2025-05-10T11:33:51.444398Z","shell.execute_reply":"2025-05-10T11:33:51.447294Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(base_model_id, device_map=\"auto\")\nmodel = PeftModel.from_pretrained(model, adapter_id)\n\ntokenizer = AutoTokenizer.from_pretrained(adapter_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T11:33:58.721548Z","iopub.execute_input":"2025-05-10T11:33:58.721870Z","iopub.status.idle":"2025-05-10T11:35:36.952788Z","shell.execute_reply.started":"2025-05-10T11:33:58.721846Z","shell.execute_reply":"2025-05-10T11:35:36.951846Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluating model using cosine Similarity","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\n\ndef cosine_sim_torch(pred_emb: torch.Tensor, ref_emb: torch.Tensor) -> float:\n    pred_norm = F.normalize(pred_emb, p=2, dim=-1)\n    ref_norm = F.normalize(ref_emb, p=2, dim=-1)\n    return torch.sum(pred_norm * ref_norm).item()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T11:48:07.192094Z","iopub.execute_input":"2025-05-10T11:48:07.192923Z","iopub.status.idle":"2025-05-10T11:48:07.197602Z","shell.execute_reply.started":"2025-05-10T11:48:07.192896Z","shell.execute_reply":"2025-05-10T11:48:07.196881Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm import tqdm\nimport torch.nn.functional as F\n\ndef test_qa_gen_model_full(model, tokenizer, raw_dataset, dataloader, device):\n    model.eval()\n    results = []\n    total = 0\n    total_score = 0.0\n\n    for i, batch in enumerate(tqdm(dataloader, desc=\"Evaluating QA Generation Model\")):\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n\n        with torch.no_grad():\n            generated_ids = model.generate(\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                max_new_tokens=64,\n                temperature=0.7\n            )\n\n        gen_texts = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n\n        labels = batch[\"labels\"]\n        labels[labels == -100] = tokenizer.pad_token_id\n        ref_texts = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n        for j, (gen, ref) in enumerate(zip(gen_texts, ref_texts)):\n            idx = i * dataloader.batch_size + j\n            if idx >= len(raw_dataset):\n                continue\n            example = raw_dataset[idx]\n\n            gen_ids = tokenizer(gen, return_tensors=\"pt\", truncation=True, padding=True)[\"input_ids\"].float()\n            ref_ids = tokenizer(ref, return_tensors=\"pt\", truncation=True, padding=True)[\"input_ids\"].float()\n\n            max_len = max(gen_ids.shape[-1], ref_ids.shape[-1])\n            gen_ids = F.pad(gen_ids, (0, max_len - gen_ids.shape[-1]))\n            ref_ids = F.pad(ref_ids, (0, max_len - ref_ids.shape[-1]))\n\n            score = cosine_sim_torch(gen_ids.squeeze(), ref_ids.squeeze())\n\n            total += 1\n            total_score += score\n\n            results.append({\n                \"context\": example[\"context\"],\n                \"question\": example[\"question\"],\n                \"reference_answer\": example[\"answers\"],\n                \"generated_answer\": gen.strip(),\n                \"cosine_similarity\": score\n            })\n\n    avg_score = total_score / total if total > 0 else 0.0\n    print(f\"Average Cosine Similarity over {total} examples: {avg_score:.4f}\")\n    return results\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T12:03:14.701642Z","iopub.execute_input":"2025-05-10T12:03:14.702510Z","iopub.status.idle":"2025-05-10T12:03:14.711537Z","shell.execute_reply.started":"2025-05-10T12:03:14.702483Z","shell.execute_reply":"2025-05-10T12:03:14.710749Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results = test_qa_gen_model_full(\n    model=model,\n    tokenizer=tokenizer,\n    raw_dataset=val_dataset_qa_gen,\n    dataloader=val_dataloader_qa_gen,\n    device=model.device,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T12:10:00.951631Z","iopub.execute_input":"2025-05-10T12:10:00.952264Z","iopub.status.idle":"2025-05-10T14:19:24.273389Z","shell.execute_reply.started":"2025-05-10T12:10:00.952241Z","shell.execute_reply":"2025-05-10T14:19:24.272628Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for r in range(10,15,1):\n    print(\"Context:\", results[r][\"question\"])\n    print(\"Question:\", results[r][\"question\"])\n    print(\"Reference:\", results[r][\"reference_answer\"])\n    print(\"Generated:\", results[r][\"generated_answer\"])\n    print(f\"Cosine Similarity: {results[r]['cosine_similarity']:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T14:45:09.578466Z","iopub.execute_input":"2025-05-10T14:45:09.578817Z","iopub.status.idle":"2025-05-10T14:45:09.586115Z","shell.execute_reply.started":"2025-05-10T14:45:09.578794Z","shell.execute_reply":"2025-05-10T14:45:09.585574Z"}},"outputs":[],"execution_count":null}]}