{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4549051,"sourceType":"datasetVersion","datasetId":2655917}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-10T15:23:51.474589Z","iopub.execute_input":"2025-05-10T15:23:51.474862Z","iopub.status.idle":"2025-05-10T15:23:51.733270Z","shell.execute_reply.started":"2025-05-10T15:23:51.474839Z","shell.execute_reply":"2025-05-10T15:23:51.732703Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/introducing-quail-a-comprehensive-reading-compre/validation.csv\n/kaggle/input/introducing-quail-a-comprehensive-reading-compre/train.csv\n/kaggle/input/introducing-quail-a-comprehensive-reading-compre/challenge.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T15:23:51.734186Z","iopub.execute_input":"2025-05-10T15:23:51.734502Z","iopub.status.idle":"2025-05-10T15:23:51.737792Z","shell.execute_reply.started":"2025-05-10T15:23:51.734484Z","shell.execute_reply":"2025-05-10T15:23:51.737243Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!pip install -U bitsandbytes\n!pip install transformers datasets torch accelerate evaluate rouge_score\n!pip install huggingface_hub","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T15:23:51.750915Z","iopub.execute_input":"2025-05-10T15:23:51.751141Z","iopub.status.idle":"2025-05-10T15:25:20.343479Z","shell.execute_reply.started":"2025-05-10T15:23:51.751125Z","shell.execute_reply":"2025-05-10T15:25:20.342391Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\nRequirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.5.1+cu124)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.0->bitsandbytes)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.0->bitsandbytes)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.0->bitsandbytes)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.0->bitsandbytes)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.0->bitsandbytes)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.0->bitsandbytes)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nDownloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.45.5 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.3.0)\nCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.4.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=6cf32ccf91c17afd86516c98cb0dafa1dcf091e5e6ac6d6387b7fe1b57dbab32\n  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\nSuccessfully built rouge_score\nInstalling collected packages: fsspec, rouge_score, evaluate\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed evaluate-0.4.3 fsspec-2024.12.0 rouge_score-0.1.2\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.30.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2024.12.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.13.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.1.31)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom datasets import Dataset\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling\nfrom peft import LoraConfig, get_peft_model\nfrom transformers  import BitsAndBytesConfig\nimport torch\nfrom torch.utils.data import DataLoader\nfrom huggingface_hub import login\nimport torch.nn as nn\nimport re\nimport pandas as pd\nimport re\nfrom datasets import Dataset\nfrom sklearn.model_selection import train_test_split\nfrom transformers import AutoTokenizer\nimport os\nimport torch\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T15:38:25.706230Z","iopub.execute_input":"2025-05-10T15:38:25.706898Z","iopub.status.idle":"2025-05-10T15:38:25.711318Z","shell.execute_reply.started":"2025-05-10T15:38:25.706874Z","shell.execute_reply":"2025-05-10T15:38:25.710606Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from huggingface_hub import login\n\n# Replace with your Hugging Face token\nlogin(token=\"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\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T15:38:26.753032Z","iopub.execute_input":"2025-05-10T15:38:26.753308Z","iopub.status.idle":"2025-05-10T15:38:26.854635Z","shell.execute_reply.started":"2025-05-10T15:38:26.753291Z","shell.execute_reply":"2025-05-10T15:38:26.853920Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def fix_answer_string(answer_str):\n    if not isinstance(answer_str, str):\n        return []\n    cleaned = re.sub(r\"'\\s+'\", \"', '\", answer_str)\n    try:\n        return eval(cleaned)\n    except:\n        return []\n\ndef get_target_text(row):\n    try:\n        if isinstance(row[\"answers\"], list) and 0 <= row[\"correct_answer_id\"] < len(row[\"answers\"]):\n            return row[\"answers\"][row[\"correct_answer_id\"]]\n    except:\n        pass\n    return None\n\ndef reformat_df_cleaned(df_cleaned):\n    df_reformatted = df_cleaned.copy()\n    df_reformatted['parsed_answer'] = df_reformatted['answers'].apply(\n        lambda x: x if isinstance(x, str) else \"not enough information\"\n    )\n    df_reformatted['prompt'] = (\n        \"### Context:\\n\" + df_reformatted['context'] + \"\\n\\n\" +\n        \"### Question:\\n\" + df_reformatted['question'] + \"\\n\\n\" +\n        \"### Instruction:\\nProvide the answer to the question based on the context.\\n\\n\" +\n        \"### Answer:\\n\" + df_reformatted['parsed_answer']\n    )\n    df_reformatted = df_reformatted.drop(columns=['parsed_answer'])\n    return df_reformatted\n\ndef tokenize_function(example):\n    prompt = example[\"prompt\"]\n    tokenized = tokenizer(prompt, padding=\"max_length\", truncation=True, max_length=256)\n    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()  # Causal LM learns from full input\n    return tokenized","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndf = pd.read_csv(\"/kaggle/input/introducing-quail-a-comprehensive-reading-compre/train.csv\")\ndf_cleaned = df[[\"context\", \"question\", \"answers\", \"correct_answer_id\"]]\ndf_cleaned = df_cleaned[df_cleaned['question'].str.endswith('?', na=False)]\ndf_cleaned = df_cleaned.reset_index(drop=True)\n\ndf_cleaned[\"answers\"] = df_cleaned[\"answers\"].apply(fix_answer_string)\ndf_cleaned[\"answers\"] = df_cleaned.apply(get_target_text, axis=1)\n\ntrain_df, val_df = train_test_split(df_cleaned, test_size=0.2, random_state=42)\ntrain_df_qa_answer = reformat_df_cleaned(train_df)\nval_df_qa_answer = reformat_df_cleaned(val_df)\n\ntrain_dataset_qa_answer = Dataset.from_pandas(train_df_qa_answer)\nval_dataset_qa_answer = Dataset.from_pandas(val_df_qa_answer)\n\ntokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\ntokenizer.pad_token = tokenizer.eos_token  \n\ntrain_qa_answer_tokenized = train_dataset_qa_answer.map(\n    tokenize_function,\n    remove_columns=[\"prompt\", \"context\", \"question\", \"answers\", \"correct_answer_id\"]\n)\n\nval_qa_answer_tokenized = val_dataset_qa_answer.map(\n    tokenize_function,\n    remove_columns=[\"prompt\", \"context\", \"question\", \"answers\", \"correct_answer_id\"]\n)\n\ntrain_qa_answer_tokenized.set_format(\"torch\")\nval_qa_answer_tokenized.set_format(\"torch\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T15:38:26.985062Z","iopub.execute_input":"2025-05-10T15:38:26.985287Z","iopub.status.idle":"2025-05-10T15:38:41.496015Z","shell.execute_reply.started":"2025-05-10T15:38:26.985269Z","shell.execute_reply":"2025-05-10T15:38:41.495324Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.10k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f87f00c151b4519995f5645526faebb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2b2bc2c60014aceb6280770fb08ee1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8afee1e4243b470ebbd93e741a1cb3cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ef8c07c4fc74501af88e93eee508b80"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6260 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f07511b231d040859d6b892af5f5af0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1566 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fdacf5f68434ae8bbdb76570584899b"}},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"bnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_use_double_quant=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T15:38:42.552391Z","iopub.execute_input":"2025-05-10T15:38:42.552875Z","iopub.status.idle":"2025-05-10T15:38:42.558192Z","shell.execute_reply.started":"2025-05-10T15:38:42.552851Z","shell.execute_reply":"2025-05-10T15:38:42.557495Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(\n    \"mistralai/Mistral-7B-Instruct-v0.1\",\n    quantization_config=bnb_config,\n    device_map=\"cuda:0\",\n    torch_dtype=torch.float16\n)\nmodel.config.pad_token_id = tokenizer.pad_token_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T15:38:43.785837Z","iopub.execute_input":"2025-05-10T15:38:43.786100Z","iopub.status.idle":"2025-05-10T15:39:59.732102Z","shell.execute_reply.started":"2025-05-10T15:38:43.786084Z","shell.execute_reply":"2025-05-10T15:39:59.731370Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b93612c51fd24f188bf10729de3f4454"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b18dfab5351d48b3a2968350c724c801"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db757ab5eec44876834baae8686480f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d367dace70fa435e98786424b27df5e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26075a7643f741d7a8b9bc7890b5a576"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06920ff5438e49af8cafeab23ad40071"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fd89951e60f44cabd455fde2c3e5474"}},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"lora_config = LoraConfig(\n    r=8,\n    lora_alpha=32,\n    target_modules=[\"q_proj\", \"v_proj\"],\n    lora_dropout=0.1,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\nmodel = get_peft_model(model, lora_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T15:39:59.733239Z","iopub.execute_input":"2025-05-10T15:39:59.733503Z","iopub.status.idle":"2025-05-10T15:39:59.848887Z","shell.execute_reply.started":"2025-05-10T15:39:59.733475Z","shell.execute_reply":"2025-05-10T15:39:59.848161Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"from torch.optim import AdamW\nbatch_size = 4\ngradient_accumulation_steps = 16\nnum_train_epochs = 3\nlearning_rate = 2e-4\noptimizer = AdamW(model.parameters(), lr=2e-5)\n\ndevice = torch.device(\"cuda:0\")\noutput_dir = \"./mistral_finetuned\"\n\ntrain_dataloader_qa_answer = DataLoader(\n    train_qa_answer_tokenized,\n    batch_size=batch_size,\n    shuffle=True,\n    collate_fn=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n)\nval_dataloader_qa_answer = DataLoader(\n    val_qa_answer_tokenized,\n    batch_size=batch_size,\n    shuffle=False,\n    collate_fn=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T15:40:13.096906Z","iopub.execute_input":"2025-05-10T15:40:13.097664Z","iopub.status.idle":"2025-05-10T15:40:13.105278Z","shell.execute_reply.started":"2025-05-10T15:40:13.097641Z","shell.execute_reply":"2025-05-10T15:40:13.104624Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def train_model(model, train_dataloader, val_dataloader, output_dir, task_name, repo_name, access_token,\n                tokenizer, optimizer, num_train_epochs, gradient_accumulation_steps, device):\n    model.train()\n    total_steps = (len(train_dataloader) // gradient_accumulation_steps) * num_train_epochs\n    step = 0\n\n    for epoch in range(num_train_epochs):\n        total_loss = 0\n        for batch_idx, batch in enumerate(train_dataloader):\n            try:\n                input_ids = batch[\"input_ids\"].to(device)\n                attention_mask = batch[\"attention_mask\"].to(device)\n                labels = batch[\"labels\"].to(device)\n\n                outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n                loss = outputs.loss\n                if loss is None or not loss.requires_grad:\n                    print(\"Error: Loss does not require grad or is None\")\n                    print(f\"Batch index: {batch_idx}\")\n                    continue\n\n                loss = loss / gradient_accumulation_steps\n                total_loss += loss.item() * gradient_accumulation_steps\n\n                loss.backward()\n\n                if (batch_idx + 1) % gradient_accumulation_steps == 0:\n                    optimizer.step()\n                    optimizer.zero_grad()\n                    step += 1\n                    print(f\"Epoch {epoch+1}, Step {step}/{total_steps}, Loss: {total_loss / (batch_idx + 1):.4f}\")\n\n            except torch.cuda.OutOfMemoryError as e:\n                print(f\"CUDA Out of Memory Error: {e}\")\n                print(\"Consider reducing batch size or enabling gradient accumulation.\")\n                torch.cuda.empty_cache()\n                continue\n            except RuntimeError as e:\n                print(f\"Runtime Error during training: {e}\")\n                continue\n\n        model.eval()\n        val_loss = 0\n        with torch.no_grad():\n            for val_batch in val_dataloader:\n                input_ids = val_batch[\"input_ids\"].to(device)\n                attention_mask = val_batch[\"attention_mask\"].to(device)\n                labels = val_batch[\"labels\"].to(device)\n                outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n                val_loss += outputs.loss.item()\n        val_loss /= len(val_dataloader)\n        print(f\"Epoch {epoch+1}, Validation Loss: {val_loss:.4f}\")\n        model.train()\n\n        local_save_path = f\"{output_dir}/{task_name}\"\n        os.makedirs(local_save_path, exist_ok=True)\n        model.save_pretrained(local_save_path)\n        tokenizer.save_pretrained(local_save_path)\n        print(f\"Model and tokenizer saved locally to {local_save_path}\")\n\n        model.eval()\n\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T15:40:22.438117Z","iopub.execute_input":"2025-05-10T15:40:22.438410Z","iopub.status.idle":"2025-05-10T15:40:22.448271Z","shell.execute_reply.started":"2025-05-10T15:40:22.438389Z","shell.execute_reply":"2025-05-10T15:40:22.447441Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"repo_name_qa_answer = \"DohaHemdann/mistral_qa_answer2epochs\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T15:40:26.804779Z","iopub.execute_input":"2025-05-10T15:40:26.805283Z","iopub.status.idle":"2025-05-10T15:40:26.808738Z","shell.execute_reply.started":"2025-05-10T15:40:26.805260Z","shell.execute_reply":"2025-05-10T15:40:26.807964Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"access_token = \"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\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T15:40:28.441797Z","iopub.execute_input":"2025-05-10T15:40:28.442081Z","iopub.status.idle":"2025-05-10T15:40:28.445653Z","shell.execute_reply.started":"2025-05-10T15:40:28.442060Z","shell.execute_reply":"2025-05-10T15:40:28.444829Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"print(\"Training QA Answering Model...\")\ntrain_model(model, train_dataloader_qa_answer, val_dataloader_qa_answer, output_dir, \"mistral_qa_answer\", repo_name_qa_answer, access_token, tokenizer, optimizer, num_train_epochs,gradient_accumulation_steps, device )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T15:40:30.332446Z","iopub.execute_input":"2025-05-10T15:40:30.332712Z","iopub.status.idle":"2025-05-10T19:28:56.905582Z","shell.execute_reply.started":"2025-05-10T15:40:30.332693Z","shell.execute_reply":"2025-05-10T19:28:56.904973Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Training QA Answering Model...\nEpoch 1, Step 1/291, Loss: 2.3838\nEpoch 1, Step 2/291, Loss: 2.4389\nEpoch 1, Step 3/291, Loss: 2.4345\nEpoch 1, Step 4/291, Loss: 2.4421\nEpoch 1, Step 5/291, Loss: 2.4420\nEpoch 1, Step 6/291, Loss: 2.4432\nEpoch 1, Step 7/291, Loss: 2.4462\nEpoch 1, Step 8/291, Loss: 2.4452\nEpoch 1, Step 9/291, Loss: 2.4475\nEpoch 1, Step 10/291, Loss: 2.4453\nEpoch 1, Step 11/291, Loss: 2.4530\nEpoch 1, Step 12/291, Loss: 2.4562\nEpoch 1, Step 13/291, Loss: 2.4629\nEpoch 1, Step 14/291, Loss: 2.4590\nEpoch 1, Step 15/291, Loss: 2.4501\nEpoch 1, Step 16/291, Loss: 2.4492\nEpoch 1, Step 17/291, Loss: 2.4442\nEpoch 1, Step 18/291, Loss: 2.4402\nEpoch 1, Step 19/291, Loss: 2.4382\nEpoch 1, Step 20/291, Loss: 2.4380\nEpoch 1, Step 21/291, Loss: 2.4322\nEpoch 1, Step 22/291, Loss: 2.4244\nEpoch 1, Step 23/291, Loss: 2.4230\nEpoch 1, Step 24/291, Loss: 2.4220\nEpoch 1, Step 25/291, Loss: 2.4224\nEpoch 1, Step 26/291, Loss: 2.4213\nEpoch 1, Step 27/291, Loss: 2.4241\nEpoch 1, Step 28/291, Loss: 2.4229\nEpoch 1, Step 29/291, Loss: 2.4197\nEpoch 1, Step 30/291, Loss: 2.4189\nEpoch 1, Step 31/291, Loss: 2.4189\nEpoch 1, Step 32/291, Loss: 2.4177\nEpoch 1, Step 33/291, Loss: 2.4171\nEpoch 1, Step 34/291, Loss: 2.4172\nEpoch 1, Step 35/291, Loss: 2.4166\nEpoch 1, Step 36/291, Loss: 2.4149\nEpoch 1, Step 37/291, Loss: 2.4151\nEpoch 1, Step 38/291, Loss: 2.4157\nEpoch 1, Step 39/291, Loss: 2.4150\nEpoch 1, Step 40/291, Loss: 2.4142\nEpoch 1, Step 41/291, Loss: 2.4121\nEpoch 1, Step 42/291, Loss: 2.4106\nEpoch 1, Step 43/291, Loss: 2.4107\nEpoch 1, Step 44/291, Loss: 2.4077\nEpoch 1, Step 45/291, Loss: 2.4080\nEpoch 1, Step 46/291, Loss: 2.4070\nEpoch 1, Step 47/291, Loss: 2.4056\nEpoch 1, Step 48/291, Loss: 2.4038\nEpoch 1, Step 49/291, Loss: 2.4029\nEpoch 1, Step 50/291, Loss: 2.4025\nEpoch 1, Step 51/291, Loss: 2.4005\nEpoch 1, Step 52/291, Loss: 2.4005\nEpoch 1, Step 53/291, Loss: 2.3992\nEpoch 1, Step 54/291, Loss: 2.3984\nEpoch 1, Step 55/291, Loss: 2.3965\nEpoch 1, Step 56/291, Loss: 2.3943\nEpoch 1, Step 57/291, Loss: 2.3931\nEpoch 1, Step 58/291, Loss: 2.3923\nEpoch 1, Step 59/291, Loss: 2.3920\nEpoch 1, Step 60/291, Loss: 2.3912\nEpoch 1, Step 61/291, Loss: 2.3907\nEpoch 1, Step 62/291, Loss: 2.3906\nEpoch 1, Step 63/291, Loss: 2.3908\nEpoch 1, Step 64/291, Loss: 2.3905\nEpoch 1, Step 65/291, Loss: 2.3896\nEpoch 1, Step 66/291, Loss: 2.3893\nEpoch 1, Step 67/291, Loss: 2.3898\nEpoch 1, Step 68/291, Loss: 2.3887\nEpoch 1, Step 69/291, Loss: 2.3882\nEpoch 1, Step 70/291, Loss: 2.3883\nEpoch 1, Step 71/291, Loss: 2.3867\nEpoch 1, Step 72/291, Loss: 2.3867\nEpoch 1, Step 73/291, Loss: 2.3866\nEpoch 1, Step 74/291, Loss: 2.3851\nEpoch 1, Step 75/291, Loss: 2.3836\nEpoch 1, Step 76/291, Loss: 2.3834\nEpoch 1, Step 77/291, Loss: 2.3835\nEpoch 1, Step 78/291, Loss: 2.3817\nEpoch 1, Step 79/291, Loss: 2.3819\nEpoch 1, Step 80/291, Loss: 2.3816\nEpoch 1, Step 81/291, Loss: 2.3790\nEpoch 1, Step 82/291, Loss: 2.3791\nEpoch 1, Step 83/291, Loss: 2.3779\nEpoch 1, Step 84/291, Loss: 2.3786\nEpoch 1, Step 85/291, Loss: 2.3797\nEpoch 1, Step 86/291, Loss: 2.3798\nEpoch 1, Step 87/291, Loss: 2.3793\nEpoch 1, Step 88/291, Loss: 2.3794\nEpoch 1, Step 89/291, Loss: 2.3793\nEpoch 1, Step 90/291, Loss: 2.3793\nEpoch 1, Step 91/291, Loss: 2.3803\nEpoch 1, Step 92/291, Loss: 2.3798\nEpoch 1, Step 93/291, Loss: 2.3798\nEpoch 1, Step 94/291, Loss: 2.3815\nEpoch 1, Step 95/291, Loss: 2.3818\nEpoch 1, Step 96/291, Loss: 2.3825\nEpoch 1, Step 97/291, Loss: 2.3826\nEpoch 1, Validation Loss: 2.4423\nModel and tokenizer saved locally to ./mistral_finetuned/mistral_qa_answer\nEpoch 2, Step 98/291, Loss: 2.4467\nEpoch 2, Step 99/291, Loss: 2.4313\nEpoch 2, Step 100/291, Loss: 2.4479\nEpoch 2, Step 101/291, Loss: 2.4557\nEpoch 2, Step 102/291, Loss: 2.4259\nEpoch 2, Step 103/291, Loss: 2.4157\nEpoch 2, Step 104/291, Loss: 2.4221\nEpoch 2, Step 105/291, Loss: 2.4275\nEpoch 2, Step 106/291, Loss: 2.4305\nEpoch 2, Step 107/291, Loss: 2.4406\nEpoch 2, Step 108/291, Loss: 2.4399\nEpoch 2, Step 109/291, Loss: 2.4391\nEpoch 2, Step 110/291, Loss: 2.4359\nEpoch 2, Step 111/291, Loss: 2.4410\nEpoch 2, Step 112/291, Loss: 2.4454\nEpoch 2, Step 113/291, Loss: 2.4454\nEpoch 2, Step 114/291, Loss: 2.4465\nEpoch 2, Step 115/291, Loss: 2.4445\nEpoch 2, Step 116/291, Loss: 2.4467\nEpoch 2, Step 117/291, Loss: 2.4499\nEpoch 2, Step 118/291, Loss: 2.4455\nEpoch 2, Step 119/291, Loss: 2.4492\nEpoch 2, Step 120/291, Loss: 2.4466\nEpoch 2, Step 121/291, Loss: 2.4451\nEpoch 2, Step 122/291, Loss: 2.4451\nEpoch 2, Step 123/291, Loss: 2.4472\nEpoch 2, Step 124/291, Loss: 2.4516\nEpoch 2, Step 125/291, Loss: 2.4555\nEpoch 2, Step 126/291, Loss: 2.4580\nEpoch 2, Step 127/291, Loss: 2.4629\nEpoch 2, Step 128/291, Loss: 2.4647\nEpoch 2, Step 129/291, Loss: 2.4657\nEpoch 2, Step 130/291, Loss: 2.4711\nEpoch 2, Step 131/291, Loss: 2.4720\nEpoch 2, Step 132/291, Loss: 2.4754\nEpoch 2, Step 133/291, Loss: 2.4753\nEpoch 2, Step 134/291, Loss: 2.4776\nEpoch 2, Step 135/291, Loss: 2.4799\nEpoch 2, Step 136/291, Loss: 2.4814\nEpoch 2, Step 137/291, Loss: 2.4833\nEpoch 2, Step 138/291, Loss: 2.4855\nEpoch 2, Step 139/291, Loss: 2.4846\nEpoch 2, Step 140/291, Loss: 2.4852\nEpoch 2, Step 141/291, Loss: 2.4871\nEpoch 2, Step 142/291, Loss: 2.4890\nEpoch 2, Step 143/291, Loss: 2.4890\nEpoch 2, Step 144/291, Loss: 2.4897\nEpoch 2, Step 145/291, Loss: 2.4909\nEpoch 2, Step 146/291, Loss: 2.4907\nEpoch 2, Step 147/291, Loss: 2.4933\nEpoch 2, Step 148/291, Loss: 2.4940\nEpoch 2, Step 149/291, Loss: 2.4948\nEpoch 2, Step 150/291, Loss: 2.4950\nEpoch 2, Step 151/291, Loss: 2.4967\nEpoch 2, Step 152/291, Loss: 2.4982\nEpoch 2, Step 153/291, Loss: 2.4995\nEpoch 2, Step 154/291, Loss: 2.5019\nEpoch 2, Step 155/291, Loss: 2.5036\nEpoch 2, Step 156/291, Loss: 2.5021\nEpoch 2, Step 157/291, Loss: 2.5035\nEpoch 2, Step 158/291, Loss: 2.5053\nEpoch 2, Step 159/291, Loss: 2.5079\nEpoch 2, Step 160/291, Loss: 2.5086\nEpoch 2, Step 161/291, Loss: 2.5110\nEpoch 2, Step 162/291, Loss: 2.5118\nEpoch 2, Step 163/291, Loss: 2.5122\nEpoch 2, Step 164/291, Loss: 2.5140\nEpoch 2, Step 165/291, Loss: 2.5155\nEpoch 2, Step 166/291, Loss: 2.5167\nEpoch 2, Step 167/291, Loss: 2.5182\nEpoch 2, Step 168/291, Loss: 2.5196\nEpoch 2, Step 169/291, Loss: 2.5223\nEpoch 2, Step 170/291, Loss: 2.5233\nEpoch 2, Step 171/291, Loss: 2.5230\nEpoch 2, Step 172/291, Loss: 2.5231\nEpoch 2, Step 173/291, Loss: 2.5240\nEpoch 2, Step 174/291, Loss: 2.5228\nEpoch 2, Step 175/291, Loss: 2.5223\nEpoch 2, Step 176/291, Loss: 2.5236\nEpoch 2, Step 177/291, Loss: 2.5228\nEpoch 2, Step 178/291, Loss: 2.5230\nEpoch 2, Step 179/291, Loss: 2.5246\nEpoch 2, Step 180/291, Loss: 2.5247\nEpoch 2, Step 181/291, Loss: 2.5249\nEpoch 2, Step 182/291, Loss: 2.5265\nEpoch 2, Step 183/291, Loss: 2.5271\nEpoch 2, Step 184/291, Loss: 2.5260\nEpoch 2, Step 185/291, Loss: 2.5257\nEpoch 2, Step 186/291, Loss: 2.5259\nEpoch 2, Step 187/291, Loss: 2.5270\nEpoch 2, Step 188/291, Loss: 2.5282\nEpoch 2, Step 189/291, Loss: 2.5293\nEpoch 2, Step 190/291, Loss: 2.5312\nEpoch 2, Step 191/291, Loss: 2.5310\nEpoch 2, Step 192/291, Loss: 2.5318\nEpoch 2, Step 193/291, Loss: 2.5318\nEpoch 2, Step 194/291, Loss: 2.5320\nEpoch 2, Validation Loss: 2.5733\nModel and tokenizer saved locally to ./mistral_finetuned/mistral_qa_answer\nEpoch 3, Step 195/291, Loss: 2.4556\nEpoch 3, Step 196/291, Loss: 2.5323\nEpoch 3, Step 197/291, Loss: 2.5506\nEpoch 3, Step 198/291, Loss: 2.5707\nEpoch 3, Step 199/291, Loss: 2.5759\nEpoch 3, Step 200/291, Loss: 2.5865\nEpoch 3, Step 201/291, Loss: 2.5877\nEpoch 3, Step 202/291, Loss: 2.5827\nEpoch 3, Step 203/291, Loss: 2.5788\nEpoch 3, Step 204/291, Loss: 2.5782\nEpoch 3, Step 205/291, Loss: 2.5683\nEpoch 3, Step 206/291, Loss: 2.5586\nEpoch 3, Step 207/291, Loss: 2.5554\nEpoch 3, Step 208/291, Loss: 2.5545\nEpoch 3, Step 209/291, Loss: 2.5581\nEpoch 3, Step 210/291, Loss: 2.5567\nEpoch 3, Step 211/291, Loss: 2.5559\nEpoch 3, Step 212/291, Loss: 2.5568\nEpoch 3, Step 213/291, Loss: 2.5542\nEpoch 3, Step 214/291, Loss: 2.5569\nEpoch 3, Step 215/291, Loss: 2.5592\nEpoch 3, Step 216/291, Loss: 2.5619\nEpoch 3, Step 217/291, Loss: 2.5647\nEpoch 3, Step 218/291, Loss: 2.5680\nEpoch 3, Step 219/291, Loss: 2.5672\nEpoch 3, Step 220/291, Loss: 2.5664\nEpoch 3, Step 221/291, Loss: 2.5668\nEpoch 3, Step 222/291, Loss: 2.5652\nEpoch 3, Step 223/291, Loss: 2.5636\nEpoch 3, Step 224/291, Loss: 2.5645\nEpoch 3, Step 225/291, Loss: 2.5627\nEpoch 3, Step 226/291, Loss: 2.5666\nEpoch 3, Step 227/291, Loss: 2.5672\nEpoch 3, Step 228/291, Loss: 2.5675\nEpoch 3, Step 229/291, Loss: 2.5685\nEpoch 3, Step 230/291, Loss: 2.5683\nEpoch 3, Step 231/291, Loss: 2.5676\nEpoch 3, Step 232/291, Loss: 2.5697\nEpoch 3, Step 233/291, Loss: 2.5690\nEpoch 3, Step 234/291, Loss: 2.5687\nEpoch 3, Step 235/291, Loss: 2.5675\nEpoch 3, Step 236/291, Loss: 2.5675\nEpoch 3, Step 237/291, Loss: 2.5655\nEpoch 3, Step 238/291, Loss: 2.5647\nEpoch 3, Step 239/291, Loss: 2.5628\nEpoch 3, Step 240/291, Loss: 2.5622\nEpoch 3, Step 241/291, Loss: 2.5619\nEpoch 3, Step 242/291, Loss: 2.5597\nEpoch 3, Step 243/291, Loss: 2.5602\nEpoch 3, Step 244/291, Loss: 2.5602\nEpoch 3, Step 245/291, Loss: 2.5591\nEpoch 3, Step 246/291, Loss: 2.5585\nEpoch 3, Step 247/291, Loss: 2.5577\nEpoch 3, Step 248/291, Loss: 2.5568\nEpoch 3, Step 249/291, Loss: 2.5575\nEpoch 3, Step 250/291, Loss: 2.5579\nEpoch 3, Step 251/291, Loss: 2.5571\nEpoch 3, Step 252/291, Loss: 2.5565\nEpoch 3, Step 253/291, Loss: 2.5542\nEpoch 3, Step 254/291, Loss: 2.5533\nEpoch 3, Step 255/291, Loss: 2.5529\nEpoch 3, Step 256/291, Loss: 2.5515\nEpoch 3, Step 257/291, Loss: 2.5509\nEpoch 3, Step 258/291, Loss: 2.5486\nEpoch 3, Step 259/291, Loss: 2.5494\nEpoch 3, Step 260/291, Loss: 2.5488\nEpoch 3, Step 261/291, Loss: 2.5491\nEpoch 3, Step 262/291, Loss: 2.5491\nEpoch 3, Step 263/291, Loss: 2.5495\nEpoch 3, Step 264/291, Loss: 2.5477\nEpoch 3, Step 265/291, Loss: 2.5470\nEpoch 3, Step 266/291, Loss: 2.5468\nEpoch 3, Step 267/291, Loss: 2.5467\nEpoch 3, Step 268/291, Loss: 2.5476\nEpoch 3, Step 269/291, Loss: 2.5476\nEpoch 3, Step 270/291, Loss: 2.5478\nEpoch 3, Step 271/291, Loss: 2.5471\nEpoch 3, Step 272/291, Loss: 2.5461\nEpoch 3, Step 273/291, Loss: 2.5446\nEpoch 3, Step 274/291, Loss: 2.5455\nEpoch 3, Step 275/291, Loss: 2.5451\nEpoch 3, Step 276/291, Loss: 2.5447\nEpoch 3, Step 277/291, Loss: 2.5445\nEpoch 3, Step 278/291, Loss: 2.5434\nEpoch 3, Step 279/291, Loss: 2.5430\nEpoch 3, Step 280/291, Loss: 2.5427\nEpoch 3, Step 281/291, Loss: 2.5420\nEpoch 3, Step 282/291, Loss: 2.5424\nEpoch 3, Step 283/291, Loss: 2.5417\nEpoch 3, Step 284/291, Loss: 2.5415\nEpoch 3, Step 285/291, Loss: 2.5418\nEpoch 3, Step 286/291, Loss: 2.5411\nEpoch 3, Step 287/291, Loss: 2.5410\nEpoch 3, Step 288/291, Loss: 2.5409\nEpoch 3, Step 289/291, Loss: 2.5409\nEpoch 3, Step 290/291, Loss: 2.5403\nEpoch 3, Step 291/291, Loss: 2.5401\nEpoch 3, Validation Loss: 2.5202\nModel and tokenizer saved locally to ./mistral_finetuned/mistral_qa_answer\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): MistralForCausalLM(\n      (model): MistralModel(\n        (embed_tokens): Embedding(32000, 4096)\n        (layers): ModuleList(\n          (0-31): 32 x MistralDecoderLayer(\n            (self_attn): MistralAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n            )\n            (mlp): MistralMLP(\n              (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n              (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n              (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n              (act_fn): SiLU()\n            )\n            (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n            (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n          )\n        )\n        (norm): MistralRMSNorm((4096,), eps=1e-05)\n        (rotary_emb): MistralRotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"repo_name = \"Dohahemdann/mistral_qa_answer2epochs\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T19:28:56.906656Z","iopub.execute_input":"2025-05-10T19:28:56.906845Z","iopub.status.idle":"2025-05-10T19:28:56.910304Z","shell.execute_reply.started":"2025-05-10T19:28:56.906831Z","shell.execute_reply":"2025-05-10T19:28:56.909655Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"access_token = \"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\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T19:28:56.911044Z","iopub.execute_input":"2025-05-10T19:28:56.911610Z","iopub.status.idle":"2025-05-10T19:28:56.926156Z","shell.execute_reply.started":"2025-05-10T19:28:56.911593Z","shell.execute_reply":"2025-05-10T19:28:56.925543Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"model.push_to_hub(repo_name, token=access_token)\ntokenizer.push_to_hub(repo_name, token=access_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T19:28:56.927536Z","iopub.execute_input":"2025-05-10T19:28:56.927769Z","iopub.status.idle":"2025-05-10T19:29:06.629542Z","shell.execute_reply.started":"2025-05-10T19:28:56.927754Z","shell.execute_reply":"2025-05-10T19:29:06.628865Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/13.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b2ac61e3f5f417899bd825c14ddff4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7d8466b5a794bc7a9771e73c8a0a5bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b1b784f44e14ac2861d6c1eaaa02dfa"}},"metadata":{}},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Dohahemdann/mistral_qa_answer2epochs/commit/4d626b99959ddb131f8b72f4b614283348d812b6', commit_message='Upload tokenizer', commit_description='', oid='4d626b99959ddb131f8b72f4b614283348d812b6', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Dohahemdann/mistral_qa_answer2epochs', endpoint='https://huggingface.co', repo_type='model', repo_id='Dohahemdann/mistral_qa_answer2epochs'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}