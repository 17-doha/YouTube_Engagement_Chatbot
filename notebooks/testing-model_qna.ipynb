{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4549051,"sourceType":"datasetVersion","datasetId":2655917}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:20:53.257518Z","iopub.execute_input":"2025-05-10T21:20:53.258067Z","iopub.status.idle":"2025-05-10T21:20:53.536802Z","shell.execute_reply.started":"2025-05-10T21:20:53.258032Z","shell.execute_reply":"2025-05-10T21:20:53.536186Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/introducing-quail-a-comprehensive-reading-compre/validation.csv\n/kaggle/input/introducing-quail-a-comprehensive-reading-compre/train.csv\n/kaggle/input/introducing-quail-a-comprehensive-reading-compre/challenge.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install transformers datasets torch pandas evaluate ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:20:53.537818Z","iopub.execute_input":"2025-05-10T21:20:53.538272Z","iopub.status.idle":"2025-05-10T21:22:28.331725Z","shell.execute_reply.started":"2025-05-10T21:20:53.538252Z","shell.execute_reply":"2025-05-10T21:22:28.331014Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, evaluate\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed evaluate-0.4.3 fsspec-2024.12.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install -U bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:22:28.333250Z","iopub.execute_input":"2025-05-10T21:22:28.333493Z","iopub.status.idle":"2025-05-10T21:22:34.473544Z","shell.execute_reply.started":"2025-05-10T21:22:28.333473Z","shell.execute_reply":"2025-05-10T21:22:34.472650Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\nRequirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.5.1+cu124)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.12.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nDownloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.45.5\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install huggingface_hub","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:22:34.474589Z","iopub.execute_input":"2025-05-10T21:22:34.474876Z","iopub.status.idle":"2025-05-10T21:22:37.594529Z","shell.execute_reply.started":"2025-05-10T21:22:34.474827Z","shell.execute_reply":"2025-05-10T21:22:37.593535Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.30.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2024.12.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.13.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.1.31)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom datasets import Dataset\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer\nfrom transformers import DataCollatorForSeq2Seq\nfrom transformers import TrainingArguments\nfrom transformers import Trainer\nimport re\nimport pandas as pd\nimport torch\nfrom torch.utils.data import DataLoader\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:22:37.596312Z","iopub.execute_input":"2025-05-10T21:22:37.596582Z","iopub.status.idle":"2025-05-10T21:23:07.058963Z","shell.execute_reply.started":"2025-05-10T21:22:37.596560Z","shell.execute_reply":"2025-05-10T21:23:07.058115Z"}},"outputs":[{"name":"stderr","text":"2025-05-10 21:22:47.928622: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746912168.233312      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746912168.303238      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from huggingface_hub import login\n\n# Replace with your Hugging Face token\nlogin(token=\"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\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:25:06.678364Z","iopub.execute_input":"2025-05-10T21:25:06.678940Z","iopub.status.idle":"2025-05-10T21:25:06.741450Z","shell.execute_reply.started":"2025-05-10T21:25:06.678915Z","shell.execute_reply":"2025-05-10T21:25:06.740728Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/introducing-quail-a-comprehensive-reading-compre/train.csv\")\ndf_cleaned = df[[\"context\", \"question\", \"answers\", \"correct_answer_id\"]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:25:06.883943Z","iopub.execute_input":"2025-05-10T21:25:06.884208Z","iopub.status.idle":"2025-05-10T21:25:07.086708Z","shell.execute_reply.started":"2025-05-10T21:25:06.884190Z","shell.execute_reply":"2025-05-10T21:25:07.086095Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def get_target_text(row):\n    try:\n        if isinstance(row[\"answers\"], list) and 0 <= row[\"correct_answer_id\"] < len(row[\"answers\"]):\n            return row[\"answers\"][row[\"correct_answer_id\"]]\n    except:\n        pass\n    return None\ndef fix_answer_string(answer_str):\n    if not isinstance(answer_str, str):\n        return []\n    cleaned = re.sub(r\"'\\s+'\", \"', '\", answer_str)\n    try:\n        return eval(cleaned)\n    except:\n        return []\ndef reformat_df_cleaned(df_cleaned):\n    df_reformatted = df_cleaned.copy()\n    df_reformatted['parsed_answer'] = df_reformatted['answers'].apply(\n        lambda x: x if isinstance(x, str) else \"not enough information\"\n    )\n    df_reformatted['prompt'] = (\n        \"### Context:\\n\" + df_reformatted['context'] + \"\\n\\n\" +\n        \"### Question:\\n\" + df_reformatted['question'] + \"\\n\\n\" +\n        \"### Instruction:\\nProvide the answer to the question based on the context.\\n\\n\" +\n        \"### Answer:\\n\" + df_reformatted['parsed_answer']\n    )\n    df_reformatted = df_reformatted.drop(columns=['parsed_answer'])\n    return df_reformatted\ndef tokenize_function(example):\n    prompt = example[\"prompt\"]\n    tokenized = tokenizer(prompt, padding=\"max_length\", truncation=True, max_length=256)\n    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()  # Causal LM learns from full input\n    return tokenized","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:25:07.879289Z","iopub.execute_input":"2025-05-10T21:25:07.879922Z","iopub.status.idle":"2025-05-10T21:25:07.886426Z","shell.execute_reply.started":"2025-05-10T21:25:07.879900Z","shell.execute_reply":"2025-05-10T21:25:07.885727Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"df_cleaned = df_cleaned[df_cleaned['question'].str.endswith('?', na=False)]\ndf_cleaned = df_cleaned.reset_index(drop=True)\ndf_cleaned[\"answers\"] = df_cleaned[\"answers\"].apply(fix_answer_string)\ndf_cleaned[\"answers\"] = df_cleaned.apply(get_target_text, axis=1)\n\ntrain_df, val_df = train_test_split(df_cleaned, test_size=0.2, random_state=42)\ntrain_df_qa_answer = reformat_df_cleaned(train_df)\nval_df_qa_answer = reformat_df_cleaned(val_df)\n\ntrain_dataset_qa_answer = Dataset.from_pandas(train_df_qa_answer)\nval_dataset_qa_answer = Dataset.from_pandas(val_df_qa_answer)\n\ntokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\ntokenizer.pad_token = tokenizer.eos_token  \n\ntrain_qa_answer_tokenized = train_dataset_qa_answer.map(\n    tokenize_function,\n    remove_columns=[\"prompt\", \"context\", \"question\", \"answers\", \"correct_answer_id\"]\n)\n\nval_qa_answer_tokenized = val_dataset_qa_answer.map(\n    tokenize_function,\n    remove_columns=[\"prompt\", \"context\", \"question\", \"answers\", \"correct_answer_id\"]\n)\n\ntrain_qa_answer_tokenized.set_format(\"torch\")\nval_qa_answer_tokenized.set_format(\"torch\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T21:25:08.804261Z","iopub.execute_input":"2025-05-10T21:25:08.804878Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.10k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1be08a93c5d14d7bbf5a4355fa590c1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2754811c8434b1db2ec8926c634c6bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b026af0bc73b41f984dc8b5577f3652c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ac7ce37093e42cf885636e9002f84c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6260 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2d4f832cad041fdbc7b6e6f3df29f39"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"batch_size = 4","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataloader_qa_answer = DataLoader(\n    train_qa_answer_tokenized,\n    batch_size=batch_size,\n    shuffle=True,\n    collate_fn=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n)\nval_dataloader_qa_answer = DataLoader(\n    val_qa_answer_tokenized,\n    batch_size=batch_size,\n    shuffle=False,\n    collate_fn=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import gc\nimport torch \ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from peft import PeftModel\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nbase_model_id = \"mistralai/Mistral-7B-Instruct-v0.1\"  \nadapter_id = \"Dohahemdann/mistral_qa_answerNEWepochs\"\n\nmodel = AutoModelForCausalLM.from_pretrained(base_model_id, device_map=\"auto\")\nmodel = PeftModel.from_pretrained(model, adapter_id)\n\ntokenizer = AutoTokenizer.from_pretrained(adapter_id)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:25:30.924648Z","iopub.execute_input":"2025-05-10T20:25:30.924885Z","iopub.status.idle":"2025-05-10T20:27:03.212071Z","shell.execute_reply.started":"2025-05-10T20:25:30.924859Z","shell.execute_reply":"2025-05-10T20:27:03.21145Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nfrom sentence_transformers import SentenceTransformer\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\ndef cosine_sim_torch(pred_emb: torch.Tensor, ref_emb: torch.Tensor) -> float:\n    pred_norm = F.normalize(pred_emb, p=2, dim=-1)\n    ref_norm = F.normalize(ref_emb, p=2, dim=-1)\n    return torch.sum(pred_norm * ref_norm).item()\n\ndef evaluate_model_with_cosine_sim(model, tokenizer, dataset_df, dataloader, device, num_batches=5):\n    model.eval()\n    results = []\n    total = 0\n    total_score = 0.0\n    sentence_model = SentenceTransformer('all-MiniLM-L6-v2') \n\n    for i, batch in enumerate(tqdm(dataloader, desc=\"Evaluating with Cosine Similarity\")):\n        if i >= num_batches:\n            break\n\n        start_idx = i * dataloader.batch_size\n        end_idx = min((i + 1) * dataloader.batch_size, len(dataset_df))\n        batch_df = dataset_df.iloc[start_idx:end_idx]\n\n        for j, (_, row) in enumerate(batch_df.iterrows()):\n            context = row[\"context\"]\n            question = row[\"question\"]\n            reference_answer = row[\"answers\"] \n            prompt = (\n                f\"Context: {context}\\n\"\n                f\"Question: {question}\\n\"\n                f\"Instruction: Answer concisely in 1-5 words based on the context.\\n\"\n                f\"Answer: \"\n            )\n\n            inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n            input_ids = inputs[\"input_ids\"]\n            attention_mask = inputs[\"attention_mask\"]\n\n            with torch.no_grad():\n                outputs = model.generate(\n                    input_ids=input_ids,\n                    attention_mask=attention_mask,\n                    max_new_tokens=30,\n                    pad_token_id=tokenizer.pad_token_id,\n                    eos_token_id=tokenizer.eos_token_id,\n                    do_sample=False\n                )\n\n            generated_text = tokenizer.decode(outputs[0][input_ids.shape[-1]:], skip_special_tokens=True).strip()\n   \n            generated_text = \" \".join(generated_text.split()[:5])\n\n            if total == 0:\n                print(\"\\n\" + \"=\"*60)\n                print(f\"ğŸ§  Context: {context[:200]}...\")  \n                print(f\"â“ Question: {question}\")\n                print(f\"âœ… Reference Answer: {reference_answer}\")\n                print(f\"ğŸ¤– Generated Answer: {generated_text}\")\n                print(\"=\"*60)\n\n            try:\n                gen_emb = torch.tensor(sentence_model.encode(generated_text, convert_to_numpy=True))\n                ref_emb = torch.tensor(sentence_model.encode(reference_answer, convert_to_numpy=True))\n                score = cosine_sim_torch(gen_emb, ref_emb)\n            except Exception as e:\n                print(f\"Error computing embeddings for index {start_idx + j}: {e}\")\n                score = 0.0\n\n            results.append({\n                \"context\": context,\n                \"question\": question,\n                \"reference_answer\": reference_answer,\n                \"generated_answer\": generated_text,\n                \"cosine_similarity\": score\n            })\n\n            total += 1\n            total_score += score\n\n    avg_score = total_score / total if total > 0 else 0.0\n    print(f\"\\nâœ… Average Cosine Similarity over {total} samples: {avg_score:.4f}\")\n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:27:03.212952Z","iopub.execute_input":"2025-05-10T20:27:03.213218Z","iopub.status.idle":"2025-05-10T20:27:03.511202Z","shell.execute_reply.started":"2025-05-10T20:27:03.213197Z","shell.execute_reply":"2025-05-10T20:27:03.510414Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results = evaluate_model_with_cosine_sim(\n    model=model,\n    tokenizer=tokenizer,\n    dataset_df=df_cleaned,  \n    dataloader=val_dataloader_qa_answer,\n    device=model.device,\n    num_batches=100\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:27:03.51208Z","iopub.execute_input":"2025-05-10T20:27:03.512376Z","iopub.status.idle":"2025-05-10T20:49:58.110665Z","shell.execute_reply.started":"2025-05-10T20:27:03.512349Z","shell.execute_reply":"2025-05-10T20:49:58.109825Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef chunk_text(token_ids, max_length):\n    return [token_ids[i:i + max_length] for i in range(0, len(token_ids), max_length)]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T19:57:45.369733Z","iopub.execute_input":"2025-05-10T19:57:45.369988Z","iopub.status.idle":"2025-05-10T19:57:45.374023Z","shell.execute_reply.started":"2025-05-10T19:57:45.369965Z","shell.execute_reply":"2025-05-10T19:57:45.373341Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"context = \"\"\"\n    '''WASHINGTON â€” U.S. President Barack Obama has shortened the sentences of 214 inmates of U.S.\n    federal prisons, in what the White House called the largest batch of commutations on a single day in more than a century.\n    \\nThe early release is part of Obama\\'s effort to correct what he views as unreasonably long mandatory minimum sentences.\n    \\nThe president\\'s push to lessen the burden on nonviolent drug offenders reflects his long-stated view that the nation should remedy the consequences of decades of onerous sentencing rules,\n     which have put tens of thousands of Americans behind bars for far too long.\\nAmong those affected by Wednesday\\'s presidential order were 67 individuals serving\n\n      life sentences - almost all for nonviolent drug crimes, although a few also were charged with firearms violations related to their drug activities.\\nTo date,\n       Obama has granted 562 commutations, more than the previous nine presidents combined, and more clemency actions that by any other president in nearly a century.\\nWhite House counsel Neil Eggleston said in the White House blog that Obama examines each clemency application on its specific merits to identify the appropriate relief, including whether the prisoner would be helped by additional drug treatment, educational programs or counseling.\\nPresidents tend to use their powers to commute sentences or issue pardons more frequently near the end of their terms of office. Administration officials said the rapid pace will continue before Obama\\'s leaves the White House in January 2017.\\n\"We are not done yet,\" Deputy Attorney General Sally Yates said. \"We expect that many more men and women will be given a second chance through the clemency initiative.\"\\nObama has long called for phasing out strict sentences for drug offenses, arguing they lead to excessive punishment and incarceration rates unseen in other developed countries. With presidential support, the Justice Department in recent years has directed prosecutors to rein in the use of harsh mandatory minimums.\\nEggleston once again called on Congress to pass legislation overhauling the U.S. criminal justice system.\\n\"It is critical that both the House and the Senate continue to work on a bipartisan basis to get a criminal justice reform bill to the president\\'s desk,\" he wrote. '''\n\n\"\"\"\nquestion = \"Who made the largest batch of commutations on a single day?\"\n\nprompt = (\n    f\"Context:\\n{context}\\n\\n\"\n    f\"Question: {question}\\n\"\n    \"Answer the question based only on the context above. Just return the answer in this format:\\n\"\n    \"Answer: <your short answer here>\\n\"\n    \"Answer:\"\n)\n\ninputs = tokenizer(prompt, return_tensors=\"pt\", padding=True)\ninput_ids = inputs[\"input_ids\"]\nattention_mask = inputs[\"attention_mask\"]\n\noutputs = model.generate(\n    input_ids=input_ids,\n    attention_mask=attention_mask,\n    max_new_tokens=50,\n    pad_token_id=tokenizer.eos_token_id,\n)\n\ngenerated_text = tokenizer.decode(outputs[0][input_ids.shape[-1]:], skip_special_tokens=True)\nprint(\"Answer:\" + generated_text.strip())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T19:57:45.374899Z","iopub.execute_input":"2025-05-10T19:57:45.375237Z","iopub.status.idle":"2025-05-10T19:57:48.757422Z","shell.execute_reply.started":"2025-05-10T19:57:45.375213Z","shell.execute_reply":"2025-05-10T19:57:48.756515Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"generated_text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T16:35:26.385275Z","iopub.execute_input":"2025-05-10T16:35:26.385547Z","iopub.status.idle":"2025-05-10T16:35:26.389982Z","shell.execute_reply.started":"2025-05-10T16:35:26.385529Z","shell.execute_reply":"2025-05-10T16:35:26.389305Z"}},"outputs":[],"execution_count":null}]}